{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chemical Space, QSAR, and Model Pitfalls\n",
        "\n",
        "## 90-Minute Laboratory ‚Äî Teacher's Reference Solution\n",
        "\n",
        "This notebook explores fundamental concepts in computational drug discovery:\n",
        "\n",
        "1. **Chemical Space Exploration** ‚Äî How molecules are represented and visualized\n",
        "2. **Activity Cliffs** ‚Äî Pairs of structurally similar molecules with drastically different activities\n",
        "3. **QSAR Modeling** ‚Äî Quantitative Structure-Activity Relationship prediction\n",
        "4. **Dataset Splitting Strategies** ‚Äî Why the choice of train/test split matters dramatically\n",
        "5. **Model Explainability** ‚Äî Understanding what drives predictions\n",
        "\n",
        "### Dataset\n",
        "We use the **SARS-CoV-2 Main Protease (Mpro)** inhibitor dataset from the COVID Moonshot project:\n",
        "- Source: [QSAR Activity Cliff Experiments](https://github.com/MarkusFerdinandDablander/QSAR-activity-cliff-experiments)\n",
        "- Target: IC50 values for Mpro inhibition\n",
        "- Molecules: ~1000 compounds with experimental measurements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# IMPORTS\n",
        "# ============================================================================\n",
        "# Core scientific stack\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# RDKit for cheminformatics\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, DataStructs, Descriptors\n",
        "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
        "from rdkit.ML.Cluster import Butina\n",
        "from rdkit.Chem.Draw import SimilarityMaps, MolsToGridImage, rdMolDraw2D\n",
        "\n",
        "# Machine learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.stats import spearmanr\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Dimensionality reduction\n",
        "import umap\n",
        "\n",
        "# Display utilities\n",
        "from IPython.display import display\n",
        "import warnings\n",
        "from io import BytesIO\n",
        "from PIL import Image as PILImage\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"All imports successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Global Parameters\n",
        "\n",
        "Key configuration values for reproducibility:\n",
        "- **IC50_CENSOR_THRESHOLD**: Measurements above this value are \"censored\" (e.g., \">100 ŒºM\" means we only know it's inactive)\n",
        "- **FP_RADIUS / FP_BITS**: Morgan fingerprint parameters (radius=2 gives ECFP4-like fingerprints)\n",
        "- **RANDOM_SEED**: For reproducibility across runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# GLOBAL PARAMETERS\n",
        "# ============================================================================\n",
        "\n",
        "CSV_URL = (\n",
        "    \"https://raw.githubusercontent.com/\"\n",
        "    \"MarkusFerdinandDablander/QSAR-activity-cliff-experiments/main/\"\n",
        "    \"data/postera_sars_cov_2_mpro/molecule_data_clean.csv\"\n",
        ")\n",
        "\n",
        "IC50_CENSOR_THRESHOLD = 99.0  # ŒºM ‚Äî compounds with IC50 > this are censored\n",
        "FP_RADIUS = 2                 # Morgan fingerprint radius (2 = ECFP4-like)\n",
        "FP_BITS = 2048                # Number of bits in fingerprint vector\n",
        "RANDOM_SEED = 42              # For reproducibility\n",
        "\n",
        "np.random.seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading & Cleaning\n",
        "\n",
        "### Why pKi instead of IC50?\n",
        "\n",
        "IC50 values span several orders of magnitude (nM to mM), making them difficult to model directly. We convert to **pKi** (negative log of IC50 in molar):\n",
        "\n",
        "$$\\text{pKi} = -\\log_{10}(\\text{IC50}_M)$$\n",
        "\n",
        "This transformation:\n",
        "- Converts multiplicative relationships to additive ones\n",
        "- Makes the distribution more normal\n",
        "- Puts values on a more intuitive scale (higher = more potent)\n",
        "\n",
        "### Censored Measurements\n",
        "\n",
        "Many compounds have IC50 reported as \">100 ŒºM\" (meaning: too weak to measure accurately). These **right-censored** values are problematic because:\n",
        "1. We don't know the true value ‚Äî only that it exceeds a threshold\n",
        "2. Including them as if they were exact measurements biases the model\n",
        "3. They cluster at the threshold, creating artificial patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# DATA LOADING & CLEANING FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def load_dataset(url: str) -> pd.DataFrame:\n",
        "    \"\"\"Load the SARS-CoV-2 Mpro inhibitor dataset from GitHub.\"\"\"\n",
        "    df = pd.read_csv(url)\n",
        "    assert \"SMILES\" in df.columns, \"Missing SMILES column\"\n",
        "    assert \"f_avg_IC50 [uM]\" in df.columns, \"Missing IC50 column\"\n",
        "    \n",
        "    df = df[[\"SMILES\", \"f_avg_IC50 [uM]\"]].copy()\n",
        "    df.rename(columns={\"f_avg_IC50 [uM]\": \"IC50_uM\"}, inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def remove_censored_measurements(df: pd.DataFrame, threshold: float) -> pd.DataFrame:\n",
        "    \"\"\"Remove compounds with IC50 above the censoring threshold.\"\"\"\n",
        "    before = len(df)\n",
        "    df = df[df[\"IC50_uM\"] <= threshold].copy()\n",
        "    after = len(df)\n",
        "    \n",
        "    print(f\"[INFO] Removed {before - after} censored molecules (IC50 > {threshold} ŒºM)\")\n",
        "    print(f\"[INFO] Remaining: {after} molecules\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def smiles_to_mol(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Parse SMILES strings into RDKit molecule objects.\"\"\"\n",
        "    mols = []\n",
        "    valid_rows = []\n",
        "    \n",
        "    for idx, smi in enumerate(df[\"SMILES\"]):\n",
        "        mol = Chem.MolFromSmiles(smi)\n",
        "        if mol is not None:\n",
        "            mols.append(mol)\n",
        "            valid_rows.append(idx)\n",
        "    \n",
        "    df = df.iloc[valid_rows].copy()\n",
        "    df[\"mol\"] = mols\n",
        "    print(f\"[INFO] Successfully parsed {len(mols)} molecules\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def ic50_to_pki(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Convert IC50 (ŒºM) to pKi = -log10(IC50 in M).\"\"\"\n",
        "    df[\"IC50_M\"] = df[\"IC50_uM\"] * 1e-6\n",
        "    df[\"pKi\"] = -np.log10(df[\"IC50_M\"])\n",
        "    return df\n",
        "\n",
        "\n",
        "def add_basic_descriptors(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Calculate basic molecular descriptors (Lipinski-like).\"\"\"\n",
        "    df[\"MW\"] = df[\"mol\"].apply(Descriptors.MolWt)        # Molecular weight\n",
        "    df[\"logP\"] = df[\"mol\"].apply(Descriptors.MolLogP)    # Lipophilicity\n",
        "    df[\"HBD\"] = df[\"mol\"].apply(Descriptors.NumHDonors)  # H-bond donors\n",
        "    df[\"HBA\"] = df[\"mol\"].apply(Descriptors.NumHAcceptors)  # H-bond acceptors\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# LOAD AND PROCESS THE DATASET\n",
        "# ============================================================================\n",
        "\n",
        "# Step 1: Load raw data\n",
        "df = load_dataset(CSV_URL)\n",
        "print(f\"Loaded {len(df)} molecules\")\n",
        "print(f\"IC50 range: {df['IC50_uM'].min():.3f} - {df['IC50_uM'].max():.3f} ŒºM\")\n",
        "\n",
        "# Step 2: Convert to pKi (before censoring, for comparison)\n",
        "df = ic50_to_pki(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# VISUALIZATION FUNCTION\n",
        "# ============================================================================\n",
        "\n",
        "def plot_pki_distribution(df: pd.DataFrame, title_suffix: str = \"\") -> None:\n",
        "    \"\"\"Plot the distribution of pKi values.\"\"\"\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.histplot(df[\"pKi\"], bins=40, kde=True, color=\"steelblue\")\n",
        "    plt.xlabel(\"pKi (higher = more potent)\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.title(f\"pKi Distribution {title_suffix}\")\n",
        "    plt.axvline(df[\"pKi\"].median(), color=\"red\", linestyle=\"--\", label=f\"Median: {df['pKi'].median():.2f}\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "# Plot BEFORE removing censored values\n",
        "plot_pki_distribution(df, \"(BEFORE censoring)\")\n",
        "print(f\"\\n‚ö†Ô∏è  Notice the spike at low pKi values ‚Äî these are censored measurements!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# REMOVE CENSORED MEASUREMENTS AND FINALIZE DATA\n",
        "# ============================================================================\n",
        "\n",
        "# Step 3: Remove censored compounds\n",
        "df = remove_censored_measurements(df, threshold=IC50_CENSOR_THRESHOLD)\n",
        "\n",
        "# Step 4: Parse SMILES to RDKit molecules\n",
        "df = smiles_to_mol(df)\n",
        "\n",
        "# Step 5: Add basic descriptors\n",
        "df = add_basic_descriptors(df)\n",
        "\n",
        "# Plot AFTER censoring\n",
        "plot_pki_distribution(df, \"(AFTER censoring)\")\n",
        "\n",
        "# Show basic statistics\n",
        "print(\"\\nüìä Dataset Summary:\")\n",
        "print(df[[\"pKi\", \"MW\", \"logP\", \"HBD\", \"HBA\"]].describe().round(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Molecular Fingerprints & Chemical Space Visualization\n",
        "\n",
        "### Morgan Fingerprints (ECFP)\n",
        "\n",
        "Morgan fingerprints encode circular substructures around each atom:\n",
        "- **Radius 2** captures atom environments up to 2 bonds away (similar to ECFP4)\n",
        "- Each substructure is hashed to a bit position in a fixed-length vector\n",
        "- Similarity between molecules is measured using **Tanimoto coefficient**\n",
        "\n",
        "### UMAP Projection\n",
        "\n",
        "UMAP (Uniform Manifold Approximation and Projection) reduces the 2048-dimensional fingerprint space to 2D for visualization:\n",
        "- Uses Jaccard distance (equivalent to 1 - Tanimoto for binary vectors)\n",
        "- Preserves local neighborhood structure\n",
        "- Reveals clusters of similar molecules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# FINGERPRINT & UMAP FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def compute_fingerprints(df: pd.DataFrame) -> list:\n",
        "    \"\"\"Compute Morgan fingerprints for all molecules.\"\"\"\n",
        "    fps = [\n",
        "        AllChem.GetMorganFingerprintAsBitVect(mol, FP_RADIUS, nBits=FP_BITS)\n",
        "        for mol in df[\"mol\"]\n",
        "    ]\n",
        "    print(f\"[INFO] Computed {len(fps)} fingerprints (radius={FP_RADIUS}, bits={FP_BITS})\")\n",
        "    return fps\n",
        "\n",
        "\n",
        "def fingerprints_to_array(fps: list) -> np.ndarray:\n",
        "    \"\"\"Convert RDKit fingerprints to numpy array.\"\"\"\n",
        "    return np.array([np.array(fp) for fp in fps])\n",
        "\n",
        "\n",
        "def umap_projection(fps: list) -> np.ndarray:\n",
        "    \"\"\"Project fingerprints to 2D using UMAP.\"\"\"\n",
        "    X = fingerprints_to_array(fps)\n",
        "    reducer = umap.UMAP(\n",
        "        n_neighbors=15,\n",
        "        min_dist=0.1,\n",
        "        metric=\"jaccard\",\n",
        "        random_state=RANDOM_SEED,\n",
        "    )\n",
        "    print(\"[INFO] Running UMAP projection...\")\n",
        "    return reducer.fit_transform(X)\n",
        "\n",
        "\n",
        "def plot_umap(emb: np.ndarray, values: np.ndarray, title: str) -> None:\n",
        "    \"\"\"Plot UMAP embedding colored by a value (e.g., pKi).\"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sc = plt.scatter(emb[:, 0], emb[:, 1], c=values, cmap=\"viridis\", s=12, alpha=0.7)\n",
        "    plt.colorbar(sc, label=\"pKi\")\n",
        "    plt.xlabel(\"UMAP 1\")\n",
        "    plt.ylabel(\"UMAP 2\")\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# COMPUTE FINGERPRINTS AND VISUALIZE CHEMICAL SPACE\n",
        "# ============================================================================\n",
        "\n",
        "# Compute fingerprints\n",
        "fps = compute_fingerprints(df)\n",
        "\n",
        "# UMAP projection\n",
        "emb = umap_projection(fps)\n",
        "\n",
        "# Visualize\n",
        "plot_umap(emb, df[\"pKi\"].values, \"Chemical Space (UMAP) ‚Äî colored by pKi\")\n",
        "\n",
        "print(\"\\nüîç Observations:\")\n",
        "print(\"   - Molecules cluster by structural similarity\")\n",
        "print(\"   - Activity (color) often varies smoothly within clusters\")\n",
        "print(\"   - BUT some nearby molecules have very different activities ‚Üí Activity Cliffs!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Activity Cliffs\n",
        "\n",
        "### What are Activity Cliffs?\n",
        "\n",
        "An **activity cliff** is a pair of molecules that are:\n",
        "1. **Structurally very similar** (high Tanimoto similarity, e.g., >0.95)\n",
        "2. **Dramatically different in activity** (large ŒîpKi, e.g., >2.0 units = 100√ó difference in potency)\n",
        "\n",
        "### Why do Activity Cliffs Matter?\n",
        "\n",
        "- They reveal **SAR (Structure-Activity Relationship)** hotspots\n",
        "- Small chemical changes can have huge biological effects\n",
        "- They are **notoriously difficult for ML models** to predict\n",
        "- A model that memorizes training data will fail on cliffs in the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ACTIVITY CLIFF DETECTION\n",
        "# ============================================================================\n",
        "\n",
        "def find_activity_cliffs(\n",
        "    df: pd.DataFrame, \n",
        "    fps: list, \n",
        "    sim_threshold: float = 0.95, \n",
        "    delta_pki_threshold: float = 2.0\n",
        ") -> list:\n",
        "    \"\"\"\n",
        "    Find pairs of molecules that are structurally similar but have very different activities.\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame with pKi values\n",
        "        fps: List of fingerprints\n",
        "        sim_threshold: Minimum Tanimoto similarity to be considered \"similar\"\n",
        "        delta_pki_threshold: Minimum pKi difference to be considered a \"cliff\"\n",
        "    \n",
        "    Returns:\n",
        "        List of tuples: (idx_i, idx_j, similarity, delta_pKi)\n",
        "    \"\"\"\n",
        "    cliffs = []\n",
        "    \n",
        "    for i in range(len(df)):\n",
        "        # Compute similarity of molecule i to all others\n",
        "        sims = DataStructs.BulkTanimotoSimilarity(fps[i], fps)\n",
        "        \n",
        "        for j, sim in enumerate(sims):\n",
        "            if j <= i:  # Avoid duplicates and self-comparison\n",
        "                continue\n",
        "            if sim >= sim_threshold:\n",
        "                delta = abs(df.iloc[i][\"pKi\"] - df.iloc[j][\"pKi\"])\n",
        "                if delta >= delta_pki_threshold:\n",
        "                    cliffs.append((i, j, sim, delta))\n",
        "    \n",
        "    print(f\"[INFO] Found {len(cliffs)} activity cliffs\")\n",
        "    print(f\"       (Tanimoto ‚â• {sim_threshold}, ŒîpKi ‚â• {delta_pki_threshold})\")\n",
        "    return cliffs\n",
        "\n",
        "\n",
        "# Find activity cliffs\n",
        "cliffs = find_activity_cliffs(df, fps, sim_threshold=0.95, delta_pki_threshold=2.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# VISUALIZE ACTIVITY CLIFFS\n",
        "# ============================================================================\n",
        "\n",
        "def visualize_activity_cliffs(df: pd.DataFrame, cliffs: list, n_pairs: int = 5):\n",
        "    \"\"\"Display pairs of molecules that form activity cliffs.\"\"\"\n",
        "    if len(cliffs) == 0:\n",
        "        print(\"No activity cliffs found!\")\n",
        "        return\n",
        "    \n",
        "    # Sort by delta_pKi (most dramatic cliffs first)\n",
        "    cliffs_sorted = sorted(cliffs, key=lambda x: x[3], reverse=True)[:n_pairs]\n",
        "    \n",
        "    mols = []\n",
        "    legends = []\n",
        "    \n",
        "    for i, j, sim, delta in cliffs_sorted:\n",
        "        mols.extend([df.iloc[i][\"mol\"], df.iloc[j][\"mol\"]])\n",
        "        legends.extend([\n",
        "            f\"pKi={df.iloc[i]['pKi']:.2f}\",\n",
        "            f\"pKi={df.iloc[j]['pKi']:.2f}\\nŒî={delta:.2f}, Sim={sim:.3f}\"\n",
        "        ])\n",
        "    \n",
        "    # Draw molecules in a grid\n",
        "    img = MolsToGridImage(\n",
        "        mols, \n",
        "        molsPerRow=2, \n",
        "        subImgSize=(350, 300),\n",
        "        legends=legends\n",
        "    )\n",
        "    display(img)\n",
        "    \n",
        "    print(\"\\nüéØ Each row shows a cliff pair:\")\n",
        "    print(\"   - Left and right molecules are >95% similar\")\n",
        "    print(\"   - But their activities differ by >100√ó (ŒîpKi > 2)\")\n",
        "\n",
        "\n",
        "visualize_activity_cliffs(df, cliffs, n_pairs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Scaffold Analysis\n",
        "\n",
        "### Murcko Scaffolds\n",
        "\n",
        "The **Murcko scaffold** is the core ring system of a molecule (stripping side chains):\n",
        "- Useful for grouping molecules by chemical series\n",
        "- Important for **scaffold-based splitting** ‚Äî ensuring the model sees novel chemotypes at test time\n",
        "\n",
        "### Why Scaffold Splitting?\n",
        "\n",
        "Random splits often leak information:\n",
        "- Training and test sets may contain molecules from the same series\n",
        "- The model can \"cheat\" by memorizing series-level patterns\n",
        "- This leads to **overly optimistic** performance estimates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SCAFFOLD ANALYSIS\n",
        "# ============================================================================\n",
        "\n",
        "def compute_scaffolds(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Extract Murcko scaffolds for all molecules.\"\"\"\n",
        "    df[\"scaffold\"] = df[\"mol\"].apply(\n",
        "        lambda m: Chem.MolToSmiles(MurckoScaffold.GetScaffoldForMol(m))\n",
        "    )\n",
        "    return df\n",
        "\n",
        "\n",
        "# Compute scaffolds\n",
        "df = compute_scaffolds(df)\n",
        "\n",
        "# Statistics\n",
        "n_scaffolds = df[\"scaffold\"].nunique()\n",
        "print(f\"[INFO] Found {n_scaffolds} unique scaffolds among {len(df)} molecules\")\n",
        "print(f\"       Average molecules per scaffold: {len(df) / n_scaffolds:.1f}\")\n",
        "\n",
        "# Show most common scaffolds\n",
        "print(\"\\nüìä Top 5 most common scaffolds:\")\n",
        "print(df[\"scaffold\"].value_counts().head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Dataset Splitting Strategies\n",
        "\n",
        "We compare **4 different splitting strategies** to understand how the choice affects model evaluation:\n",
        "\n",
        "### 1. Random Split\n",
        "- Molecules are randomly assigned to train/test\n",
        "- **Problem**: Similar molecules (even from the same series) can appear in both sets\n",
        "- **Result**: Overly optimistic performance\n",
        "\n",
        "### 2. Scaffold Split\n",
        "- Entire scaffolds (chemical series) go to either train OR test\n",
        "- **Effect**: Tests generalization to new chemotypes\n",
        "- **Result**: More realistic but still may group similar scaffolds\n",
        "\n",
        "### 3. Butina Clustering Split\n",
        "- Clusters molecules by Tanimoto similarity using Butina algorithm\n",
        "- Entire clusters go to train or test\n",
        "- **Effect**: Ensures structural novelty in test set\n",
        "- **Result**: Harder than scaffold split\n",
        "\n",
        "### 4. UMAP-based Split\n",
        "- Uses UMAP 2D projection to identify spatially separated regions\n",
        "- Test set comes from distinct regions of chemical space\n",
        "- **Effect**: Maximum structural novelty\n",
        "- **Result**: The hardest, most realistic test of generalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SPLITTING FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def random_split(X: np.ndarray, y: np.ndarray, test_size: float = 0.2):\n",
        "    \"\"\"Standard random train/test split.\"\"\"\n",
        "    return train_test_split(X, y, test_size=test_size, random_state=RANDOM_SEED)\n",
        "\n",
        "\n",
        "def scaffold_split(df: pd.DataFrame, test_size: float = 0.2):\n",
        "    \"\"\"\n",
        "    Split by scaffold: entire chemical series go to train or test.\n",
        "    Returns boolean masks for train and test sets.\n",
        "    \"\"\"\n",
        "    scaffolds = df[\"scaffold\"].unique()\n",
        "    np.random.shuffle(scaffolds)\n",
        "    \n",
        "    n_test = int(test_size * len(scaffolds))\n",
        "    test_scaffolds = set(scaffolds[:n_test])\n",
        "    \n",
        "    test_mask = df[\"scaffold\"].isin(test_scaffolds)\n",
        "    train_mask = ~test_mask\n",
        "    \n",
        "    return train_mask.values, test_mask.values\n",
        "\n",
        "\n",
        "def butina_split(fps: list, cutoff: float = 0.6, test_size: float = 0.3):\n",
        "    \"\"\"\n",
        "    Cluster molecules using Butina algorithm, then split by clusters.\n",
        "    Returns boolean masks for train and test sets.\n",
        "    \"\"\"\n",
        "    # Compute pairwise distances (as required by Butina)\n",
        "    n = len(fps)\n",
        "    dists = []\n",
        "    for i in range(1, n):\n",
        "        sims = DataStructs.BulkTanimotoSimilarity(fps[i], fps[:i])\n",
        "        dists.extend([1 - s for s in sims])\n",
        "    \n",
        "    # Cluster\n",
        "    clusters = Butina.ClusterData(dists, n, cutoff, isDistData=True)\n",
        "    clusters = list(clusters)\n",
        "    np.random.shuffle(clusters)\n",
        "    \n",
        "    # Assign clusters to test set\n",
        "    n_test_clusters = int(test_size * len(clusters))\n",
        "    test_clusters = clusters[:n_test_clusters]\n",
        "    \n",
        "    test_idx = np.zeros(n, dtype=bool)\n",
        "    for cluster in test_clusters:\n",
        "        test_idx[list(cluster)] = True\n",
        "    \n",
        "    return ~test_idx, test_idx\n",
        "\n",
        "\n",
        "def umap_split(emb: np.ndarray, test_size: float = 0.2, n_regions: int = 10):\n",
        "    \"\"\"\n",
        "    Split by UMAP regions: divide 2D space into grid cells, \n",
        "    assign entire cells to train or test.\n",
        "    \n",
        "    This ensures test molecules come from distinct regions of chemical space.\n",
        "    \"\"\"\n",
        "    n = len(emb)\n",
        "    \n",
        "    # Create grid-based regions\n",
        "    x_bins = np.linspace(emb[:, 0].min(), emb[:, 0].max(), n_regions + 1)\n",
        "    y_bins = np.linspace(emb[:, 1].min(), emb[:, 1].max(), n_regions + 1)\n",
        "    \n",
        "    # Assign each point to a region\n",
        "    x_idx = np.digitize(emb[:, 0], x_bins[:-1]) - 1\n",
        "    y_idx = np.digitize(emb[:, 1], y_bins[:-1]) - 1\n",
        "    region_ids = x_idx * n_regions + y_idx\n",
        "    \n",
        "    # Get unique regions and shuffle\n",
        "    unique_regions = np.unique(region_ids)\n",
        "    np.random.shuffle(unique_regions)\n",
        "    \n",
        "    # Assign regions to test set until we reach target size\n",
        "    test_mask = np.zeros(n, dtype=bool)\n",
        "    current_test_size = 0\n",
        "    target_test_size = int(test_size * n)\n",
        "    \n",
        "    for region in unique_regions:\n",
        "        if current_test_size >= target_test_size:\n",
        "            break\n",
        "        region_mask = region_ids == region\n",
        "        test_mask |= region_mask\n",
        "        current_test_size = test_mask.sum()\n",
        "    \n",
        "    return ~test_mask, test_mask\n",
        "\n",
        "\n",
        "print(\"‚úÖ All splitting functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. QSAR Modeling\n",
        "\n",
        "### Model: XGBoost Regressor\n",
        "\n",
        "We use **XGBoost** (Gradient Boosted Trees) for QSAR modeling:\n",
        "- Works well with sparse fingerprint features\n",
        "- Handles non-linear relationships\n",
        "- Fast training on medium-sized datasets\n",
        "\n",
        "### Evaluation Metrics\n",
        "\n",
        "1. **RMSE** (Root Mean Squared Error): Measures prediction accuracy in pKi units\n",
        "2. **Spearman œÅ** (Rank Correlation): Measures ability to rank compounds correctly\n",
        "   - More important for virtual screening where we care about ranking, not absolute values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# QSAR MODELING FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def train_xgb(X_train: np.ndarray, y_train: np.ndarray) -> XGBRegressor:\n",
        "    \"\"\"Train an XGBoost regressor.\"\"\"\n",
        "    model = XGBRegressor(\n",
        "        n_estimators=300,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.05,\n",
        "        subsample=0.8,\n",
        "        random_state=RANDOM_SEED,\n",
        "        verbosity=0  # Suppress warnings\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate_model(model: XGBRegressor, X_test: np.ndarray, y_test: np.ndarray) -> dict:\n",
        "    \"\"\"Evaluate model and return metrics.\"\"\"\n",
        "    y_pred = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # Manual RMSE calculation\n",
        "    rho, pval = spearmanr(y_test, y_pred)\n",
        "    \n",
        "    return {\n",
        "        \"rmse\": rmse,\n",
        "        \"spearman_rho\": rho,\n",
        "        \"y_pred\": y_pred,\n",
        "        \"y_test\": y_test\n",
        "    }\n",
        "\n",
        "\n",
        "def plot_predictions(y_test: np.ndarray, y_pred: np.ndarray, title: str) -> None:\n",
        "    \"\"\"Plot predicted vs experimental values.\"\"\"\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.scatter(y_test, y_pred, alpha=0.5, s=20)\n",
        "    plt.xlabel(\"Experimental pKi\")\n",
        "    plt.ylabel(\"Predicted pKi\")\n",
        "    plt.title(title)\n",
        "    \n",
        "    # Add diagonal line\n",
        "    lims = [min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())]\n",
        "    plt.plot(lims, lims, \"r--\", alpha=0.8, label=\"Perfect prediction\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print(\"‚úÖ Modeling functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# COMPARE ALL SPLITTING STRATEGIES\n",
        "# ============================================================================\n",
        "\n",
        "# Prepare feature matrix and target\n",
        "X = fingerprints_to_array(fps)\n",
        "y = df[\"pKi\"].values\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"COMPARING 4 SPLITTING STRATEGIES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Store results for comparison\n",
        "results = {}\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 1. RANDOM SPLIT\n",
        "# -------------------------------------------------------------------------\n",
        "print(\"\\nüìä 1. RANDOM SPLIT\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "X_train, X_test, y_train, y_test = random_split(X, y)\n",
        "print(f\"   Train: {len(y_train)}, Test: {len(y_test)}\")\n",
        "\n",
        "model_random = train_xgb(X_train, y_train)\n",
        "res_random = evaluate_model(model_random, X_test, y_test)\n",
        "\n",
        "print(f\"   RMSE: {res_random['rmse']:.3f}\")\n",
        "print(f\"   Spearman œÅ: {res_random['spearman_rho']:.3f}\")\n",
        "\n",
        "results[\"Random\"] = res_random\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 2. SCAFFOLD SPLIT\n",
        "# -------------------------------------------------------------------------\n",
        "print(\"\\nüìä 2. SCAFFOLD SPLIT\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "train_mask, test_mask = scaffold_split(df)\n",
        "X_train, X_test = X[train_mask], X[test_mask]\n",
        "y_train, y_test = y[train_mask], y[test_mask]\n",
        "print(f\"   Train: {len(y_train)}, Test: {len(y_test)}\")\n",
        "\n",
        "model_scaffold = train_xgb(X_train, y_train)\n",
        "res_scaffold = evaluate_model(model_scaffold, X_test, y_test)\n",
        "\n",
        "print(f\"   RMSE: {res_scaffold['rmse']:.3f}\")\n",
        "print(f\"   Spearman œÅ: {res_scaffold['spearman_rho']:.3f}\")\n",
        "\n",
        "results[\"Scaffold\"] = res_scaffold\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 3. BUTINA CLUSTERING SPLIT\n",
        "# -------------------------------------------------------------------------\n",
        "print(\"\\nüìä 3. BUTINA CLUSTERING SPLIT\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "train_mask, test_mask = butina_split(fps, cutoff=0.6)\n",
        "X_train, X_test = X[train_mask], X[test_mask]\n",
        "y_train, y_test = y[train_mask], y[test_mask]\n",
        "print(f\"   Train: {len(y_train)}, Test: {len(y_test)}\")\n",
        "\n",
        "model_butina = train_xgb(X_train, y_train)\n",
        "res_butina = evaluate_model(model_butina, X_test, y_test)\n",
        "\n",
        "print(f\"   RMSE: {res_butina['rmse']:.3f}\")\n",
        "print(f\"   Spearman œÅ: {res_butina['spearman_rho']:.3f}\")\n",
        "\n",
        "results[\"Butina\"] = res_butina\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 4. UMAP-BASED SPLIT\n",
        "# -------------------------------------------------------------------------\n",
        "print(\"\\nüìä 4. UMAP-BASED SPLIT\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "train_mask, test_mask = umap_split(emb, n_regions=8)\n",
        "X_train, X_test = X[train_mask], X[test_mask]\n",
        "y_train, y_test = y[train_mask], y[test_mask]\n",
        "print(f\"   Train: {len(y_train)}, Test: {len(y_test)}\")\n",
        "\n",
        "model_umap = train_xgb(X_train, y_train)\n",
        "res_umap = evaluate_model(model_umap, X_test, y_test)\n",
        "\n",
        "print(f\"   RMSE: {res_umap['rmse']:.3f}\")\n",
        "print(f\"   Spearman œÅ: {res_umap['spearman_rho']:.3f}\")\n",
        "\n",
        "results[\"UMAP\"] = res_umap\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# RESULTS COMPARISON\n",
        "# ============================================================================\n",
        "\n",
        "# Create comparison DataFrame\n",
        "comparison_df = pd.DataFrame({\n",
        "    \"Split\": list(results.keys()),\n",
        "    \"RMSE\": [results[k][\"rmse\"] for k in results],\n",
        "    \"Spearman œÅ\": [results[k][\"spearman_rho\"] for k in results]\n",
        "}).sort_values(\"RMSE\", ascending=False)\n",
        "\n",
        "print(\"\\nüìä RESULTS SUMMARY (sorted by difficulty - hardest first)\")\n",
        "print(\"=\" * 60)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Identify the hardest split\n",
        "hardest = comparison_df.iloc[0][\"Split\"]\n",
        "easiest = comparison_df.iloc[-1][\"Split\"]\n",
        "\n",
        "print(f\"\\nüî¥ HARDEST split: {hardest} (RMSE = {comparison_df.iloc[0]['RMSE']:.3f})\")\n",
        "print(f\"üü¢ EASIEST split: {easiest} (RMSE = {comparison_df.iloc[-1]['RMSE']:.3f})\")\n",
        "\n",
        "# Calculate performance gap\n",
        "gap_rmse = comparison_df.iloc[0][\"RMSE\"] - comparison_df.iloc[-1][\"RMSE\"]\n",
        "gap_rho = comparison_df.iloc[-1][\"Spearman œÅ\"] - comparison_df.iloc[0][\"Spearman œÅ\"]\n",
        "\n",
        "print(f\"\\n‚ö†Ô∏è  Performance gap:\")\n",
        "print(f\"   RMSE difference: {gap_rmse:.3f} pKi units\")\n",
        "print(f\"   Spearman œÅ difference: {gap_rho:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# VISUALIZE COMPARISON\n",
        "# ============================================================================\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Plot 1: RMSE comparison (bar chart)\n",
        "ax1 = axes[0]\n",
        "colors = ['#e74c3c' if s == hardest else '#3498db' for s in comparison_df[\"Split\"]]\n",
        "bars = ax1.bar(comparison_df[\"Split\"], comparison_df[\"RMSE\"], color=colors, edgecolor='black')\n",
        "ax1.set_ylabel(\"RMSE (lower is better)\")\n",
        "ax1.set_title(\"Model Performance by Split Strategy\")\n",
        "ax1.axhline(comparison_df[\"RMSE\"].mean(), color='gray', linestyle='--', alpha=0.7, label='Mean')\n",
        "ax1.legend()\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, val in zip(bars, comparison_df[\"RMSE\"]):\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
        "             f'{val:.2f}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "# Plot 2: Spearman correlation comparison\n",
        "ax2 = axes[1]\n",
        "colors = ['#e74c3c' if s == hardest else '#2ecc71' for s in comparison_df[\"Split\"]]\n",
        "bars = ax2.bar(comparison_df[\"Split\"], comparison_df[\"Spearman œÅ\"], color=colors, edgecolor='black')\n",
        "ax2.set_ylabel(\"Spearman œÅ (higher is better)\")\n",
        "ax2.set_title(\"Ranking Ability by Split Strategy\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, val in zip(bars, comparison_df[\"Spearman œÅ\"]):\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
        "             f'{val:.2f}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PREDICTION SCATTER PLOTS FOR EACH SPLIT\n",
        "# ============================================================================\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for ax, (name, res) in zip(axes, results.items()):\n",
        "    y_test = res[\"y_test\"]\n",
        "    y_pred = res[\"y_pred\"]\n",
        "    \n",
        "    ax.scatter(y_test, y_pred, alpha=0.5, s=15)\n",
        "    \n",
        "    # Diagonal line\n",
        "    lims = [min(y_test.min(), y_pred.min()) - 0.5, max(y_test.max(), y_pred.max()) + 0.5]\n",
        "    ax.plot(lims, lims, \"r--\", alpha=0.8)\n",
        "    \n",
        "    ax.set_xlabel(\"Experimental pKi\")\n",
        "    ax.set_ylabel(\"Predicted pKi\")\n",
        "    ax.set_title(f\"{name} Split\\nRMSE={res['rmse']:.2f}, œÅ={res['spearman_rho']:.2f}\")\n",
        "    ax.set_xlim(lims)\n",
        "    ax.set_ylim(lims)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüîç Observations:\")\n",
        "print(\"   - Random split shows the tightest correlation (but this is misleading!)\")\n",
        "print(\"   - Harder splits show more scatter, especially for novel chemotypes\")\n",
        "print(\"   - The model struggles when test molecules are structurally different from training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# VISUALIZE SPLITS IN CHEMICAL SPACE (UMAP)\n",
        "# ============================================================================\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "split_functions = [\n",
        "    (\"Random\", lambda: random_split(X, y)),\n",
        "    (\"Scaffold\", lambda: scaffold_split(df)),\n",
        "    (\"Butina\", lambda: butina_split(fps, cutoff=0.6)),\n",
        "    (\"UMAP\", lambda: umap_split(emb, n_regions=8))\n",
        "]\n",
        "\n",
        "for ax, (name, split_fn) in zip(axes, split_functions):\n",
        "    # Get split masks\n",
        "    if name == \"Random\":\n",
        "        # Random split returns data, not masks - we need to recreate masks\n",
        "        X_train, X_test, y_train, y_test = split_fn()\n",
        "        # We can't easily show this in UMAP space without indices\n",
        "        # So we'll just show a random 20% as \"test\"\n",
        "        test_mask = np.zeros(len(df), dtype=bool)\n",
        "        test_idx = np.random.choice(len(df), size=int(0.2*len(df)), replace=False)\n",
        "        test_mask[test_idx] = True\n",
        "    else:\n",
        "        train_mask, test_mask = split_fn()\n",
        "    \n",
        "    # Plot\n",
        "    ax.scatter(emb[~test_mask, 0], emb[~test_mask, 1], \n",
        "               c='#3498db', s=12, alpha=0.6, label='Train')\n",
        "    ax.scatter(emb[test_mask, 0], emb[test_mask, 1], \n",
        "               c='#e74c3c', s=15, alpha=0.8, label='Test')\n",
        "    \n",
        "    ax.set_title(f\"{name} Split\")\n",
        "    ax.set_xlabel(\"UMAP 1\")\n",
        "    ax.set_ylabel(\"UMAP 2\")\n",
        "    ax.legend(loc='upper right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüîç Notice how different splits distribute test molecules:\")\n",
        "print(\"   - Random: test points scattered throughout (similar to training)\")\n",
        "print(\"   - Scaffold/Butina: test points in localized clusters\")\n",
        "print(\"   - UMAP: test points in distinct regions of chemical space\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Model Explainability\n",
        "\n",
        "### Similarity Maps\n",
        "\n",
        "We can visualize which atoms contribute most to the model's prediction using **similarity maps**:\n",
        "- Red regions: increase predicted activity\n",
        "- Blue regions: decrease predicted activity\n",
        "\n",
        "This helps understand:\n",
        "- What structural features the model learned\n",
        "- Why certain predictions are wrong\n",
        "- Whether the model is learning chemically meaningful patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# MODEL EXPLAINABILITY\n",
        "# ============================================================================\n",
        "\n",
        "def explain_molecule(mol, model, title=\"\"):\n",
        "    \"\"\"Generate a similarity map showing which atoms drive the prediction.\"\"\"\n",
        "    def get_fp(m, atom_idx=-1):\n",
        "        \"\"\"Get fingerprint, optionally with a specific atom removed.\"\"\"\n",
        "        if atom_idx >= 0:\n",
        "            # Get the atom environment contribution\n",
        "            info = {}\n",
        "            fp = AllChem.GetMorganFingerprintAsBitVect(m, FP_RADIUS, nBits=FP_BITS, bitInfo=info)\n",
        "        else:\n",
        "            fp = AllChem.GetMorganFingerprintAsBitVect(m, FP_RADIUS, nBits=FP_BITS)\n",
        "        return np.array(fp)\n",
        "    \n",
        "    def predictor(m):\n",
        "        fp = get_fp(m)\n",
        "        return model.predict(fp.reshape(1, -1))[0]\n",
        "    \n",
        "    # Calculate atom contributions using Morgan fingerprint similarity map\n",
        "    try:\n",
        "        # Try newer RDKit API (2023+)\n",
        "        from rdkit.Chem.Draw.SimilarityMaps import GetSimilarityMapForFingerprint\n",
        "        \n",
        "        def fp_func(m, idx):\n",
        "            \"\"\"Function to generate fingerprint for similarity map.\"\"\"\n",
        "            return AllChem.GetMorganFingerprint(m, FP_RADIUS, fromAtoms=[idx])\n",
        "        \n",
        "        fig = SimilarityMaps.GetSimilarityMapForFingerprint(\n",
        "            mol, \n",
        "            fp_func,\n",
        "            lambda x: model.predict(fingerprints_to_array([AllChem.GetMorganFingerprintAsBitVect(x, FP_RADIUS, nBits=FP_BITS)]))[0]\n",
        "        )\n",
        "        if title:\n",
        "            plt.title(title)\n",
        "        plt.show()\n",
        "        \n",
        "    except Exception as e:\n",
        "        # Fallback: just show the molecule with prediction\n",
        "        pred = predictor(mol)\n",
        "        \n",
        "        # Draw molecule\n",
        "        from rdkit.Chem import Draw\n",
        "        img = Draw.MolToImage(mol, size=(400, 300))\n",
        "        \n",
        "        plt.figure(figsize=(5, 4))\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"{title}\\nPredicted pKi: {pred:.2f}\" if title else f\"Predicted pKi: {pred:.2f}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Use the model trained on random split (most optimistic) for explainability\n",
        "print(\"üî¨ Explaining predictions for selected molecules:\")\n",
        "print(\"   (Using model trained on random split)\\n\")\n",
        "\n",
        "# Find molecules with highest and lowest pKi\n",
        "idx_best = df[\"pKi\"].idxmax()\n",
        "idx_worst = df[\"pKi\"].idxmin()\n",
        "\n",
        "print(f\"Most potent molecule (pKi = {df.loc[idx_best, 'pKi']:.2f}):\")\n",
        "explain_molecule(df.loc[idx_best, \"mol\"], model_random)\n",
        "\n",
        "print(f\"\\nLeast potent molecule (pKi = {df.loc[idx_worst, 'pKi']:.2f}):\")\n",
        "explain_molecule(df.loc[idx_worst, \"mol\"], model_random)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ANALYZE HIGH-ERROR PREDICTIONS\n",
        "# ============================================================================\n",
        "\n",
        "# Use stored results from the UMAP split (already computed in Cell 21)\n",
        "y_test_umap = results[\"UMAP\"][\"y_test\"]\n",
        "y_pred_umap = results[\"UMAP\"][\"y_pred\"]\n",
        "\n",
        "# Calculate errors\n",
        "errors = np.abs(y_test_umap - y_pred_umap)\n",
        "error_order = np.argsort(errors)[::-1]  # Highest error first\n",
        "\n",
        "print(\"üîç Molecules with HIGHEST prediction error (UMAP split):\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Find molecules that were in the test set by matching pKi values\n",
        "# (since we stored y_test, we can find the original indices)\n",
        "test_pki_values = set(y_test_umap)\n",
        "\n",
        "# Show top 3 worst predictions\n",
        "for rank, idx in enumerate(error_order[:3]):\n",
        "    exp_val = y_test_umap[idx]\n",
        "    pred_val = y_pred_umap[idx]\n",
        "    error_val = errors[idx]\n",
        "    \n",
        "    # Find the molecule in df with this pKi value\n",
        "    matching_idx = df[np.isclose(df[\"pKi\"].values, exp_val, atol=1e-6)].index\n",
        "    \n",
        "    print(f\"\\n#{rank+1}: Error = {error_val:.2f} pKi units\")\n",
        "    print(f\"    Experimental: {exp_val:.2f}, Predicted: {pred_val:.2f}\")\n",
        "    \n",
        "    if len(matching_idx) > 0:\n",
        "        mol_idx = matching_idx[0]\n",
        "        explain_molecule(df.loc[mol_idx, \"mol\"], model_umap)\n",
        "    else:\n",
        "        print(\"    (Could not find matching molecule for visualization)\")\n",
        "\n",
        "print(\"\\nüí° High-error molecules are often:\")\n",
        "print(\"   - Activity cliffs (similar to training molecules but different activity)\")\n",
        "print(\"   - Novel scaffolds not seen during training\")\n",
        "print(\"   - Compounds with unusual substituents\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Conclusions\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. **Splitting strategy dramatically affects apparent model performance**\n",
        "   - Random splits are overly optimistic\n",
        "   - Structure-aware splits (scaffold, Butina, UMAP) give more realistic estimates\n",
        "\n",
        "2. **Activity cliffs are a fundamental challenge**\n",
        "   - Small structural changes can cause large activity differences\n",
        "   - Fingerprint-based models struggle with cliffs\n",
        "   - This is a key limitation of 2D representations\n",
        "\n",
        "3. **The \"applicability domain\" matters**\n",
        "   - Models work best within the chemical space of training data\n",
        "   - Predictions for novel chemotypes should be treated with caution\n",
        "\n",
        "4. **Explainability helps build trust**\n",
        "   - Similarity maps reveal what features drive predictions\n",
        "   - High-error predictions often have interpretable explanations\n",
        "\n",
        "### Recommendations for Real-World QSAR\n",
        "\n",
        "- Always use **structure-aware splitting** for validation\n",
        "- Report performance on multiple split types\n",
        "- Be skeptical of models with very high random-split performance\n",
        "- Consider the **applicability domain** when deploying models\n",
        "- Use **ensemble methods** to estimate prediction uncertainty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# FINAL SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üìã FINAL SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"\\nüìä Dataset: SARS-CoV-2 Mpro inhibitors\")\n",
        "print(f\"   Molecules: {len(df)}\")\n",
        "print(f\"   Unique scaffolds: {df['scaffold'].nunique()}\")\n",
        "print(f\"   Activity cliffs: {len(cliffs)}\")\n",
        "\n",
        "print(f\"\\nüèÜ SPLIT COMPARISON (ordered by difficulty):\")\n",
        "print(\"-\" * 50)\n",
        "for _, row in comparison_df.iterrows():\n",
        "    marker = \"üî¥\" if row[\"Split\"] == hardest else \"üü¢\" if row[\"Split\"] == easiest else \"üîµ\"\n",
        "    print(f\"   {marker} {row['Split']:12} RMSE={row['RMSE']:.3f}  œÅ={row['Spearman œÅ']:.3f}\")\n",
        "\n",
        "print(f\"\\n‚ö†Ô∏è  KEY INSIGHT:\")\n",
        "print(f\"   Using random split instead of {hardest} split would overestimate\")\n",
        "print(f\"   model performance by {gap_rmse:.2f} RMSE units ({gap_rho:.2f} in Spearman œÅ)\")\n",
        "\n",
        "print(\"\\n‚úÖ Laboratory complete!\")\n",
        "print(\"=\" * 70)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
